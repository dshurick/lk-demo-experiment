{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Analysis for Recommender Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will analyze and compare the generated recommendations and predictions from a predefined list of algorithms with the goal of assessing the performance of each algorithm with respect to a metric. In other words, we would rank the algorithms for each metric considered with respect to performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the list of packages required to successfully run the analysis. They are divided into partitions to signify their specific task.<br>\n",
    "We need the pathlib package for working with files and folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would use the pandas for analyzing and manipulating our data while seaborn and matplotlib are used for data visualization. statsmodels.graphics.gofplots and scipy.stats.shapiro are used for normality check. Scipy.stats.friedmanchisquare is a non-parametric test used to determine the statistical significance in metric results and the wilcoxon test is used for pairwise comparison of sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import friedmanchisquare, wilcoxon\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TQDM is useful for progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\michaelekstrand\\Anaconda3\\envs\\lk-demo\\lib\\site-packages\\tqdm\\std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And logging to show what's happening in LensKit routines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lenskit:bob\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "lk_log = logging.getLogger('lenskit')\n",
    "stream_f = logging.Formatter('%(levelname)s:%(name)s:%(message)s')\n",
    "stream_h = logging.StreamHandler(sys.stderr)\n",
    "stream_h.setFormatter(stream_f)\n",
    "lk_log.handlers.clear()\n",
    "lk_log.addHandler(stream_h)\n",
    "lk_log.setLevel(logging.INFO)\n",
    "lk_log.info('bob')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use lenskit for training, running, and evaluating recommender algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\michaelekstrand\\Anaconda3\\envs\\lk-demo\\lib\\site-packages\\fastparquet\\dataframe.py:5: FutureWarning: pandas.core.index is deprecated and will be removed in a future version.  The public classes are available in the top-level namespace.\n",
      "  from pandas.core.index import CategoricalIndex, RangeIndex, Index, MultiIndex\n"
     ]
    }
   ],
   "source": [
    "from lenskit import topn\n",
    "from lenskit.metrics.predict import rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify the dataset we will use for our analysis and the main directory from where we read the recommendation and prediction files. From the main directory we find all the directories associated with the dataset and then read the recommendation and predictions files from those directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "dataset = \"ml20m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_root = Path(\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [fld for fld in output_root.glob(f'{dataset}-*')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 83086200 entries, 0 to 83086199\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Dtype   \n",
      "---  ------     -----   \n",
      " 0   item       int64   \n",
      " 1   score      float64 \n",
      " 2   user       int64   \n",
      " 3   rank       int64   \n",
      " 4   dataset    category\n",
      " 5   algorithm  category\n",
      "dtypes: category(2), float64(1), int64(3)\n",
      "memory usage: 2.6 GB\n"
     ]
    }
   ],
   "source": [
    "recs = []\n",
    "for fld in dirs: \n",
    "    for file in fld.glob(\"recs-*\"):\n",
    "        rec = pd.read_csv(file, sep=',')\n",
    "        rec[\"dataset\"] = fld.name.split(\"-\")[0]\n",
    "        rec[\"algorithm\"] = fld.name.split(\"-\")[1]\n",
    "        recs.append(rec)\n",
    "\n",
    "recs = pd.concat(recs, ignore_index=True)\n",
    "recs = recs.astype({'dataset': 'category', 'algorithm': 'category'})\n",
    "recs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3462325 entries, 0 to 3462324\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Dtype  \n",
      "---  ------      -----  \n",
      " 0   user        int64  \n",
      " 1   item        int64  \n",
      " 2   rating      float64\n",
      " 3   timestamp   int64  \n",
      " 4   prediction  float64\n",
      " 5   dataset     object \n",
      " 6   algorithm   object \n",
      "dtypes: float64(2), int64(3), object(2)\n",
      "memory usage: 184.9+ MB\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "for fld in dirs:\n",
    "    for file in fld.glob(\"pred-*\"):\n",
    "        pred = pd.read_csv(file, sep=',')\n",
    "        pred[\"dataset\"] = fld.name.split(\"-\")[0]\n",
    "        pred[\"algorithm\"] = fld.name.split(\"-\")[1]\n",
    "        preds.append(pred)\n",
    "\n",
    "preds = pd.concat(preds, ignore_index=True)\n",
    "preds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to load the test data so that we have the ground truths for computing accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_root = Path(\"data-split\")\n",
    "split_dir = split_root / dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "for file in split_dir.glob(\"test-*.csv.gz\"):\n",
    "    test.append(pd.read_csv(file, sep=','))\n",
    "\n",
    "test = pd.concat(test, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The topn.RecListAnalysis class computes top-N metrics for recommendation list and takes care of making sure that the recommendations and ground truths are properly matched. Refer to the documentation for detailed explanation of the purpose for the RecListAnalysis class and how the analysis is done - https://lkpy.lenskit.org/en/stable/evaluation/topn-metrics.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lenskit.topn:analyzing 83086200 recommendations (692465 truth rows)\n",
      "INFO:lenskit.topn:using group columns ['user', 'dataset', 'algorithm']\n",
      "INFO:lenskit.topn:ungrouped columns: ['item', 'score', 'rank']\n",
      "INFO:lenskit.topn:using truth ID columns ['user', 'item']\n",
      "INFO:lenskit.topn:computing analysis for 830862 lists\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f9408d6fa1c43d08bc9face6b62ac2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=830862.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lenskit.topn:analyzed 830862 lists in 25m19.20s\n",
      "INFO:lenskit.topn:filling in missing user info\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>nrecs</th>\n",
       "      <th>precision</th>\n",
       "      <th>recip_rank</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>ntruth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>user</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">ml20m</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">ALS</th>\n",
       "      <th>1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.154893</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.084485</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        nrecs  precision  recip_rank      ndcg  ntruth\n",
       "dataset algorithm user                                                \n",
       "ml20m   ALS       1     100.0       0.00    0.000000  0.000000       5\n",
       "                  2     100.0       0.02    0.111111  0.154893       5\n",
       "                  3     100.0       0.00    0.000000  0.000000       5\n",
       "                  4     100.0       0.00    0.000000  0.000000       5\n",
       "                  5     100.0       0.02    0.022222  0.084485       5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rla = topn.RecListAnalysis()\n",
    "\n",
    "rla.add_metric(topn.precision)\n",
    "rla.add_metric(topn.recip_rank)\n",
    "rla.add_metric(topn.ndcg)\n",
    "results = rla.compute(recs, test, include_missing=True)\n",
    "results = results.fillna(0)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will reshape the 'results' dataframe by stacking the columns to index and then use the bar chart to visualize the performance of our algorithms with respect to the precision, reciprocal rank and ndcg metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>user</th>\n",
       "      <th>metric</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALS</td>\n",
       "      <td>1</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALS</td>\n",
       "      <td>1</td>\n",
       "      <td>recip_rank</td>\n",
       "      <td>0.010204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALS</td>\n",
       "      <td>1</td>\n",
       "      <td>ndcg</td>\n",
       "      <td>0.042241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALS</td>\n",
       "      <td>2</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALS</td>\n",
       "      <td>2</td>\n",
       "      <td>recip_rank</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  algorithm  user      metric       val\n",
       "0       ALS     1   precision  0.010000\n",
       "1       ALS     1  recip_rank  0.010204\n",
       "2       ALS     1        ndcg  0.042241\n",
       "3       ALS     2   precision  0.030000\n",
       "4       ALS     2  recip_rank  0.062500"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pltData = (results.drop(columns=['nrecs', 'ntruth']).stack()).reset_index().drop(columns=['dataset'])\n",
    "pltData.columns = ['algorithm', 'user', 'metric', 'val']\n",
    "pltData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to determine if the differences we observe in the performances of the algorithms for the various metrics are statistically significant. To achieve this, we will need to use either a parametric or non-parametric statistical test for comparing the differences. We will consider a parametric test - repeated ANOVA measure cause our sample groups are correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 777.6x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.catplot(x = \"algorithm\", y = \"val\", data = pltData, kind=\"bar\", col = \"metric\", aspect=1.2, height=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a nonparametric statistical method to check the statistical significance of the performances for the different metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Friedman Test - nonparametric version of the repeated measures ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Null hypothesis - H0: There are no differences between the related groups<br>\n",
    "* Alternative hypothesis - Ha: There are differences somewhere between the related groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_vals = []\n",
    "alg_names = []\n",
    "for alg, data in (results.reset_index()).groupby(\"algorithm\"):\n",
    "    alg_names.append(alg)\n",
    "    alg_vals.append(data[\"precision\"].to_numpy())\n",
    "\n",
    "stat, p = friedmanchisquare(alg_vals[0], alg_vals[1], alg_vals[2], alg_vals[3])\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If p < 0.05, we reject the null hypothesis in favour of the alternative hypothesis that there exists differences. However, we do not know exactly where those differences lie. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post Hoc Tests - Wilcoxon signed-rank test with Bonferroni adjustment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To examine where the differences actually occur, we need to run separate Wilcoxon signed-rank tests on the different combinations of the algorithms. (However, we only perform the Post-Hoc test when the Friedman test result is statistically significant). We need to use a Bonferroni adjustment on the results from the wilcoxon tests because we are making multiple comparisons which makes it more likely that we declare a result significant when we should not.<br><br>\n",
    "* Null hypothesis - H0: There is no difference between the paired results of the paired algorithm\n",
    "* Alternative hypothesis - Ha: There is a difference between the paired results of the paired algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_compare = list(combinations(list(range(4)), 2 ))\n",
    "\n",
    "def wilcox_bonf(data1, data2, alg_pair): \n",
    "    alpha = 0.05\n",
    "    stat, p = wilcoxon(data1, data2)\n",
    "    #Calculate Bonferroni adjustment\n",
    "    new_alpha = alpha/len(n_compare)\n",
    "    if p > new_alpha:\n",
    "        decision = 'Metric is the same (fail to reject H0)'\n",
    "    else:\n",
    "        decision = 'Metric is different (reject H0)'\n",
    "    return pd.Series({'Pair': alg_pair, 'Statistics': stat, 'p_value': p, 'Decision':decision})\n",
    "\n",
    "for idx in n_compare:\n",
    "    result = wilcox_bonf(alg_vals[idx[0]], alg_vals[idx[1]], (alg_names[idx[0]], alg_names[idx[1]]))\n",
    "    print('%s, Statistics=%.3f, p-value=%.3f, %s' % (result['Pair'], result['Statistics'], result['p_value'], result['Decision']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ndcg   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Friedman Test - nonparametric version of the repeated measures ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Null hypothesis - H0: There are no differences between the related groups<br>\n",
    "* Alternative hypothesis - Ha: There are differences somewhere between the related groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_vals = []\n",
    "alg_names = []\n",
    "for alg, data in (results.reset_index()).groupby(\"algorithm\"):\n",
    "    alg_names.append(alg)\n",
    "    alg_vals.append(data[\"ndcg\"].to_numpy())\n",
    "\n",
    "stat, p = friedmanchisquare(alg_vals[0], alg_vals[1], alg_vals[2], alg_vals[3])\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If p < 0.05, we reject the null hypothesis in favour of the alternative hypothesis that there exists differences. However, we do not know exactly where those differences lie. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post Hoc Tests - Wilcoxon signed-rank test with Bonferroni adjustment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now examine where the differences actually occur using separate Wilcoxon signed-rank tests on the different combinations of the algorithms. We then adjust the result using a Bonferroni adjustment on the results. <br><br>\n",
    "* Null hypothesis - H0: There is no difference between the paired results of the paired algorithm\n",
    "* Alternative hypothesis - Ha: There is a difference between the paired results of the paired algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_compare = list(combinations(list(range(4)), 2 ))\n",
    "\n",
    "def wilcox_bonf(data1, data2, alg_pair): \n",
    "    alpha = 0.05\n",
    "    stat, p = wilcoxon(data1, data2)\n",
    "    #Calculate Bonferroni adjustment\n",
    "    new_alpha = alpha/len(n_compare)\n",
    "    if p > new_alpha:\n",
    "        decision = 'Metric is the same (fail to reject H0)'\n",
    "    else:\n",
    "        decision = 'Metric is different (reject H0)'\n",
    "    return pd.Series({'Pair': alg_pair, 'Statistics': stat, 'p_value': p, 'Decision':decision})\n",
    "\n",
    "for idx in n_compare:\n",
    "    result = wilcox_bonf(alg_vals[idx[0]], alg_vals[idx[1]], (alg_names[idx[0]], alg_names[idx[1]]))\n",
    "    print('%s, Statistics=%.3f, p-value=%.3f, %s' % (result['Pair'], result['Statistics'], result['p_value'], result['Decision']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# recip_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Friedman Test - nonparametric version of the repeated measures ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Null hypothesis - H0: There are no differences between the related groups<br>\n",
    "* Alternative hypothesis - Ha: There are differences somewhere between the related groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_vals = []\n",
    "alg_names = []\n",
    "for alg, data in (results.reset_index()).groupby(\"algorithm\"):\n",
    "    alg_names.append(alg)\n",
    "    alg_vals.append(data[\"recip_rank\"].to_numpy())\n",
    "\n",
    "stat, p = friedmanchisquare(alg_vals[0], alg_vals[1], alg_vals[2], alg_vals[3])\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If p < 0.05, we reject the null hypothesis in favour of the alternative hypothesis that there exists differences. However, we do not know exactly where those differences lie. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post Hoc Tests - Wilcoxon signed-rank test with Bonferroni adjustment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To examine where the differences actually occur, we run separate Wilcoxon signed-rank tests on the different combinations of the algorithms. We then adjust the result using a Bonferroni adjustment. <br><br>\n",
    "* Null hypothesis - H0: There is no difference between the paired results of the paired algorithm\n",
    "* Alternative hypothesis - Ha: There is a difference between the paired results of the paired algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_compare = list(combinations(list(range(4)), 2 ))\n",
    "\n",
    "def wilcox_bonf(data1, data2, alg_pair): \n",
    "    alpha = 0.05\n",
    "    stat, p = wilcoxon(data1, data2)\n",
    "    #Calculate Bonferroni adjustment\n",
    "    new_alpha = alpha/len(n_compare)\n",
    "    if p > new_alpha:\n",
    "        decision = 'Metric is the same (fail to reject H0)'\n",
    "    else:\n",
    "        decision = 'Metric is different (reject H0)'\n",
    "    return pd.Series({'Pair': alg_pair, 'Statistics': stat, 'p_value': p, 'Decision':decision})\n",
    "\n",
    "for idx in n_compare:\n",
    "    result = wilcox_bonf(alg_vals[idx[0]], alg_vals[idx[1]], (alg_names[idx[0]], alg_names[idx[1]]))\n",
    "    print('%s, Statistics=%.3f, p-value=%.3f, %s' % (result['Pair'], result['Statistics'], result['p_value'], result['Decision']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction RMSE\n",
    "\n",
    "We will also look at the prediction RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_rmse = preds.groupby(['algorithm', 'user']).apply(lambda df: rmse(df['prediction'], df['rating']))\n",
    "user_rmse = user_rmse.reset_index(name='RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='algorithm', y='RMSE', data=user_rmse, kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
